{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution and Pool Layers-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "jpgfile = Image.open('imgs/shelf.JPG')\n",
    "\n",
    "print(jpgfile.bits, jpgfile.size, jpgfile.format)\n",
    "plt.imshow(jpgfile, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "gray_img = np.array(jpgfile).sum(2).astype('float64')/(3*255)\n",
    "plt.imshow(gray_img , cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgr_img = cv2.imread('imgs/shelf.JPG')\n",
    "bgr_img = cv2.resize(bgr_img, (0,0), fx=0.25, fy=0.25) \n",
    "gray_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY).astype(\"float32\")/255\n",
    "\n",
    "plt.imshow(gray_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Layer\n",
    "\n",
    "Suppose that out image looks like that\n",
    "![Image](imgs/image_cl.png)\n",
    "and filter\n",
    "![Image](imgs/filter_cl.png)\n",
    "Then applying filter means\n",
    "![Applaying Filters](imgs/applying_cl.gif)\n",
    "\n",
    "### Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "filter_1 = np.array([[-1, -1, 1, 1], [-1, -1, 1, 1], [-1, -1, 1, 1], [-1, -1, 1, 1]])\n",
    "filter_2 = np.array([[-1, -1, -1, -1], [-1, -1, -1, -1], [1, 1, 1, 1], [1, 1, 1, 1]])\n",
    "filter_3 = np.array([[0, -1, 0, 0], [-1, 21, -1, 0], [0, -1, 0, 0], [0, 0, 0, 0]])\n",
    "filter_4 = np.ones((4, 4))\n",
    "filters = np.array([filter_1, filter_2, filter_3, filter_4])\n",
    "\n",
    "filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change shape for expexted by pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_torch = torch.from_numpy(filters).unsqueeze(1).type(torch.FloatTensor)\n",
    "filters_params = torch.nn.Parameter(filters_torch)\n",
    "filters_params.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of filters in pytorch\n",
    "\n",
    "`[ number of output chanels, number of input chanels, hight, width]` \n",
    "\n",
    "### Change shape of image as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img_torch = torch.from_numpy(gray_img).unsqueeze(0).unsqueeze(1).type(torch.FloatTensor)\n",
    "gray_img.shape, gray_img_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: we will expain it later\n",
    "\n",
    "Here it is just to show how filters works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(Net, self).__init__()        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, bias=False)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_x = self.conv(x)\n",
    "        activated_x = F.relu(conv_x)\n",
    "        pool_x = self.pool(activated_x)\n",
    "        \n",
    "        return conv_x, activated_x, pool_x\n",
    "\n",
    "## Initialize model\n",
    "model = Net(1, 4, (4, 4))\n",
    "## Initialize weights\n",
    "model.conv.weight = filters_params\n",
    "\n",
    "# print out the layer in the network\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at output of layers\n",
    "\n",
    "##### Convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer, activated_layer, pooled_layer = model(gray_img_torch)\n",
    "conv_layer.shape, activated_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_layer(layer):\n",
    "    n_filters = layer.shape[1]\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    \n",
    "    for i in range(n_filters):\n",
    "        ax = fig.add_subplot(1, n_filters, i+1, xticks=[], yticks=[])\n",
    "        # grab layer outputs\n",
    "        ax.imshow(np.squeeze(layer[0,i].data.numpy()), cmap='gray')\n",
    "        ax.set_title('Output %s' % str(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output before activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_layer(conv_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output after activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_layer(activated_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaxPool Layer\n",
    "\n",
    "![Pooling](imgs/pool.jpeg)\n",
    "\n",
    "![Pooling](imgs/maxpool.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_layer(pooled_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before: \", activated_layer.shape)\n",
    "print(\"After: \", pooled_layer.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links\n",
    "* <https://adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/>\n",
    "* <http://cs231n.github.io/convolutional-networks/>\n",
    "* <http://udacity.com>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
