{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "![LSTM](imgs/LSTM3-chain.png)\n",
    "\n",
    "![LSTM](imgs/LSTM2-notation.png)\n",
    "\n",
    "\n",
    "\n",
    "![LSTM](imgs/LSTM3-focus-f.png)\n",
    "\n",
    "![LSTM](imgs/LSTM3-focus-i.png)\n",
    "\n",
    "![LSTM](imgs/LSTM3-focus-C.png)\n",
    "\n",
    "![LSTM](imgs/LSTM3-focus-o.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From pytorch documentation\n",
    "\n",
    "\\begin{array}{ll} \\\\\n",
    "    f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\\\\n",
    "    i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\\\\n",
    "    g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{(t-1)} + b_{hg}) \\\\\n",
    "    c_t = f_t * c_{(t-1)} + i_t * g_t \\\\\n",
    "    o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\\\    \n",
    "    h_t = o_t * \\tanh(c_t) \\\\\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to define LSTM layer in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.9371e-01, -2.0238e+00, -1.3367e+00],\n",
       "         [-7.1214e-01,  3.9357e-01, -8.0636e-01]],\n",
       "\n",
       "        [[ 1.0664e+00, -1.8921e+00,  1.1003e+00],\n",
       "         [ 9.2181e-01,  4.6061e-01, -3.7591e-01]],\n",
       "\n",
       "        [[-1.1430e+00,  1.9850e+00,  6.8247e-01],\n",
       "         [ 6.3254e-01, -1.6362e+00, -6.4329e-01]],\n",
       "\n",
       "        [[ 3.7377e-01, -4.9265e-01, -1.0238e-01],\n",
       "         [ 4.0733e-01,  6.7559e-02, -1.5383e+00]],\n",
       "\n",
       "        [[ 3.5512e-02,  7.9347e-02,  6.2202e-01],\n",
       "         [ 1.2980e+00, -1.5078e-03, -1.3330e+00]],\n",
       "\n",
       "        [[ 6.5556e-02, -2.8847e-01,  4.2900e-01],\n",
       "         [ 3.1263e-02, -5.2232e-03,  5.5556e-01]],\n",
       "\n",
       "        [[ 2.9324e-02,  2.9765e-01, -8.5468e-01],\n",
       "         [ 2.6762e-01, -3.6226e-01, -1.6829e+00]],\n",
       "\n",
       "        [[-1.8964e-01, -2.9445e-01, -8.9548e-01],\n",
       "         [-2.6878e+00, -7.7660e-01, -2.7466e-01]],\n",
       "\n",
       "        [[ 5.9321e-01, -1.4983e+00, -3.5858e-01],\n",
       "         [-6.0709e-01, -7.1092e-01, -1.6367e+00]],\n",
       "\n",
       "        [[ 4.7706e-01,  1.4737e+00, -3.9085e-01],\n",
       "         [-1.4603e+00,  4.7680e-01,  1.4279e-01]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 10\n",
    "input_size = 3\n",
    "hidden_size = 4 \n",
    "\n",
    "inputs = torch.randn(seq_len, batch_size, input_size)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hidden_0 = (h_0, c_0)\n",
    "hidden_0 = (torch.zeros(1, batch_size, hidden_size), torch.zeros(1, batch_size, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out, lstm_hidden = lstm(inputs)\n",
    "lstm_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1161, -0.0449,  0.1356, -0.0908],\n",
       "         [ 0.0797, -0.1030, -0.0519, -0.0097]],\n",
       "\n",
       "        [[ 0.2028, -0.1207,  0.0942, -0.0380],\n",
       "         [ 0.0988, -0.0903,  0.1654,  0.0538]],\n",
       "\n",
       "        [[ 0.1246, -0.0615,  0.2019, -0.0452],\n",
       "         [-0.0669, -0.2622, -0.1729,  0.1506]],\n",
       "\n",
       "        [[ 0.1125, -0.1810,  0.0160,  0.0975],\n",
       "         [ 0.0633, -0.2287, -0.0961,  0.1149]],\n",
       "\n",
       "        [[ 0.1426, -0.1711,  0.0510,  0.0349],\n",
       "         [ 0.0473, -0.2513, -0.1071,  0.0590]],\n",
       "\n",
       "        [[ 0.0526, -0.2139,  0.0484,  0.1440],\n",
       "         [ 0.0955, -0.2225,  0.0076,  0.0419]],\n",
       "\n",
       "        [[ 0.0832, -0.1676,  0.1285,  0.1490],\n",
       "         [-0.0626, -0.2704, -0.0761,  0.1422]],\n",
       "\n",
       "        [[ 0.1588, -0.0668,  0.1662, -0.1116],\n",
       "         [ 0.0823, -0.2291, -0.0254,  0.0449]],\n",
       "\n",
       "        [[ 0.1449, -0.1012,  0.1712, -0.1042],\n",
       "         [ 0.0258, -0.2339,  0.0712,  0.1279]],\n",
       "\n",
       "        [[ 0.0864, -0.1954,  0.0454,  0.1037],\n",
       "         [ 0.1143, -0.0547,  0.1980,  0.0086]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to put hidden inputs to zeros, there is no need to provide them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1161, -0.0449,  0.1356, -0.0908],\n",
       "         [ 0.0797, -0.1030, -0.0519, -0.0097]],\n",
       "\n",
       "        [[ 0.2028, -0.1207,  0.0942, -0.0380],\n",
       "         [ 0.0988, -0.0903,  0.1654,  0.0538]],\n",
       "\n",
       "        [[ 0.1246, -0.0615,  0.2019, -0.0452],\n",
       "         [-0.0669, -0.2622, -0.1729,  0.1506]],\n",
       "\n",
       "        [[ 0.1125, -0.1810,  0.0160,  0.0975],\n",
       "         [ 0.0633, -0.2287, -0.0961,  0.1149]],\n",
       "\n",
       "        [[ 0.1426, -0.1711,  0.0510,  0.0349],\n",
       "         [ 0.0473, -0.2513, -0.1071,  0.0590]],\n",
       "\n",
       "        [[ 0.0526, -0.2139,  0.0484,  0.1440],\n",
       "         [ 0.0955, -0.2225,  0.0076,  0.0419]],\n",
       "\n",
       "        [[ 0.0832, -0.1676,  0.1285,  0.1490],\n",
       "         [-0.0626, -0.2704, -0.0761,  0.1422]],\n",
       "\n",
       "        [[ 0.1588, -0.0668,  0.1662, -0.1116],\n",
       "         [ 0.0823, -0.2291, -0.0254,  0.0449]],\n",
       "\n",
       "        [[ 0.1449, -0.1012,  0.1712, -0.1042],\n",
       "         [ 0.0258, -0.2339,  0.0712,  0.1279]],\n",
       "\n",
       "        [[ 0.0864, -0.1954,  0.0454,  0.1037],\n",
       "         [ 0.1143, -0.0547,  0.1980,  0.0086]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out, lstm_hidden = lstm(inputs)\n",
    "lstm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the last output is the output of RRR. We can get it by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0864, -0.1954,  0.0454,  0.1037],\n",
       "        [ 0.1143, -0.0547,  0.1980,  0.0086]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often convient to have batches as the first dimension of the input. One can do it by adding `batch_first=True` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2054, -0.8651, -0.6088],\n",
       "         [ 1.1406,  0.6082, -1.6735],\n",
       "         [ 0.1723,  0.3467,  0.4114],\n",
       "         [-1.9259, -0.2567, -1.2048],\n",
       "         [-1.6136,  1.3430, -0.4050],\n",
       "         [ 1.1966, -1.6512, -0.6767],\n",
       "         [-0.2106, -2.3519,  0.2720],\n",
       "         [-0.1093,  1.0253, -0.1260],\n",
       "         [-1.0609,  0.8758,  0.2576],\n",
       "         [ 0.8765,  1.4954, -0.0666]],\n",
       "\n",
       "        [[-0.0217,  1.5338, -1.4219],\n",
       "         [ 0.2273, -0.3218,  0.3919],\n",
       "         [ 0.0749,  0.4817, -1.1825],\n",
       "         [ 2.1782, -0.3505,  1.3469],\n",
       "         [-0.4601,  1.3531, -0.0419],\n",
       "         [ 0.0473, -0.6126,  0.4255],\n",
       "         [-0.3531, -1.0316,  0.5059],\n",
       "         [ 0.5735,  0.4778,  0.5165],\n",
       "         [-1.7511,  0.0114, -0.2766],\n",
       "         [-1.0167,  1.3915, -0.7804]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_batch_first = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True) \n",
    "inputs_batch_first = torch.randn(batch_size, seq_len, input_size)\n",
    "inputs_batch_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0567,  0.1265,  0.0624,  0.2018],\n",
       "         [-0.1659,  0.3151, -0.1186,  0.3846],\n",
       "         [-0.1493,  0.0682, -0.0403,  0.2772],\n",
       "         [-0.3941, -0.1411,  0.0983,  0.2673],\n",
       "         [-0.4439, -0.2128, -0.0445,  0.2855],\n",
       "         [-0.1648, -0.0416,  0.0435,  0.1917],\n",
       "         [-0.0991, -0.1108,  0.0799,  0.1383],\n",
       "         [-0.1874, -0.0555,  0.0368,  0.3100],\n",
       "         [-0.2655, -0.1287,  0.0010,  0.2873],\n",
       "         [-0.1702,  0.0646, -0.2415,  0.3772]],\n",
       "\n",
       "        [[-0.1996,  0.1648, -0.2542,  0.3286],\n",
       "         [-0.1348,  0.0275, -0.0138,  0.2211],\n",
       "         [-0.2382,  0.1150, -0.0923,  0.3565],\n",
       "         [-0.0244,  0.0877, -0.0228,  0.2297],\n",
       "         [-0.1829,  0.0225, -0.1591,  0.3706],\n",
       "         [-0.1361, -0.0329,  0.0252,  0.2318],\n",
       "         [-0.1136, -0.1019,  0.1046,  0.2007],\n",
       "         [-0.1038, -0.0251,  0.0933,  0.2877],\n",
       "         [-0.3108, -0.1780,  0.1325,  0.2571],\n",
       "         [-0.3798, -0.1602, -0.0726,  0.3382]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out, lstm_hidden = lstm_batch_first(inputs_batch_first)\n",
    "lstm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we get the finial output by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1702,  0.0646, -0.2415,  0.3772],\n",
       "        [-0.3798, -0.1602, -0.0726,  0.3382]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[36, 67, 43, 95, 89,  8, 59, 93, 73, 69],\n",
       "        [47, 66, 68, 29, 70, 16, 58, 13, 37, 94]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_size = 100\n",
    "sentences = torch.randint(dict_size, (batch_size, seq_len))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 3\n",
    "embedding = nn.Embedding(dict_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0091, -0.3593, -1.0621],\n",
       "         [-1.7992, -0.0894,  1.2168],\n",
       "         [ 0.4249, -0.9113, -0.9369],\n",
       "         [ 1.7890, -1.0901,  0.7563],\n",
       "         [-0.6374,  1.1834,  0.6713],\n",
       "         [-1.2554, -1.4542, -0.3407],\n",
       "         [-1.1324, -0.4685,  0.5710],\n",
       "         [ 0.0318,  1.0612,  1.9154],\n",
       "         [ 0.0588,  0.8046,  0.2209],\n",
       "         [ 0.0756, -0.6359, -1.8824]],\n",
       "\n",
       "        [[-0.0348,  0.9834, -0.2814],\n",
       "         [ 0.1302, -0.7690, -1.2987],\n",
       "         [-1.1199, -0.3056, -0.0716],\n",
       "         [-1.2604,  1.3658,  0.7427],\n",
       "         [-1.5014,  0.6390, -0.5878],\n",
       "         [-0.7691,  1.7891,  0.6372],\n",
       "         [ 1.7406,  0.4675,  0.0660],\n",
       "         [ 1.0832, -0.4642,  0.7879],\n",
       "         [ 0.0817, -0.8927,  0.7386],\n",
       "         [-0.0728,  0.7193, -0.5492]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_embedded = embedding(sentences)\n",
    "sentences_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2681,  0.0815,  0.0451,  0.3268],\n",
       "        [-0.1928,  0.0247,  0.0008,  0.3499]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out, _ = lstm_batch_first(sentences_embedded)\n",
    "lstm_out[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing (NLP)\n",
    "\n",
    "Next we consider a dataset with text and the goal is to evaluate whether they are toxic or non-toxic.\n",
    "\n",
    "You can download the dataset in the following link:\n",
    "\n",
    "[here](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comments_df = pd.read_csv(\"data/jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "comments_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39891"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = int(len(comments_df)/4)\n",
    "comments_df = comments_df.iloc[1:n]\n",
    "len(comments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>Hello \\n\\nI guess the reqeust for the lion vs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36054</th>\n",
       "      <td>Also, you haven't said what information was de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comment_text\n",
       "3949   Hello \\n\\nI guess the reqeust for the lion vs ...\n",
       "36054  Also, you haven't said what information was de..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "label_colnames = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(comments_df[['comment_text']], comments_df[label_colnames], random_state=667)\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z .,]')\n",
    "STEMMER = SnowballStemmer('english')\n",
    "\n",
    "class TextPreprocessor:\n",
    "        \n",
    "    def transfrom_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(BAD_SYMBOLS_RE, \" \", text) # process bad symbols\n",
    "        # text = \" \".join([STEMMER.stem(word) for word in text.split()])\n",
    "        return text\n",
    "    \n",
    "    def transform(self, series):\n",
    "        return series.apply(lambda text: self.transfrom_text(text))\n",
    "    \n",
    "    def labels_to_text(self, text, extra_labels):\n",
    "        for idx in extra_labels.index:\n",
    "            aux = text.loc[[idx]]\n",
    "            text = text.append(aux.iloc[[0]])\n",
    "        return text    \n",
    "    \n",
    "    def over_sampling(self,text,labels,extra_positive):\n",
    "        extra_labels = pd.DataFrame()\n",
    "        for idx in range(len(extra_positive)):\n",
    "            target = extra_positive[idx]\n",
    "            if idx == 0:\n",
    "                extra_labels = labels.groupby([target]).get_group(1)\n",
    "            else:\n",
    "                prev_target = extra_positive[idx-1]\n",
    "                extra_labels = extra_labels[extra_labels[target] == extra_labels[prev_target]]\n",
    "        \n",
    "        labels = labels.append(extra_labels)\n",
    "        text = self.labels_to_text(text,extra_labels)\n",
    "\n",
    "        return text,labels\n",
    "    \n",
    "    def balanced_partition(self,text,labels,min_freq):\n",
    "        while True :\n",
    "            labels_dist = labels.sum()/len(labels)\n",
    "            extra_positive = []\n",
    "            for label in labels_dist.keys():\n",
    "                if labels_dist[label] < min_freq:\n",
    "                    extra_positive.append(label) \n",
    "            if len(extra_positive) == 0: \n",
    "                return text,labels\n",
    "            else: \n",
    "                text,labels = self.over_sampling(text,labels,extra_positive)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0.097232\n",
       "severe_toxic     0.010763\n",
       "obscene          0.052376\n",
       "threat           0.003443\n",
       "insult           0.049535\n",
       "identity_hate    0.008991\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TextPreprocessor()\n",
    "X_train_trs = preprocessor.transform(X_train['comment_text'])\n",
    "X_train_preprocessed, y_train = preprocessor.balanced_partition(X_train_trs,y_train,0.02)\n",
    "X_test_preprocessed = preprocessor.transform(X_test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "\n",
      " Re: Vandalism revert \n",
      "\n",
      "Thanks for the notice, repeat vandalism from multiple accounts can get messy )   \"\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "    re  vandalism revert   thanks for the notice, repeat vandalism from multiple accounts can get messy      \n"
     ]
    }
   ],
   "source": [
    "print(X_train[\"comment_text\"].iloc[0])\n",
    "print('---------------------------------------------------------------------------------------------------------------------')\n",
    "print(X_train_preprocessed.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trs = None\n",
    "X_train = None\n",
    "X_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(toxic            0.114023\n",
       " severe_toxic     0.029162\n",
       " obscene          0.070002\n",
       " threat           0.021978\n",
       " insult           0.067213\n",
       " identity_hate    0.027423\n",
       " dtype: float64, 30485, 30485)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum()/len(y_train),len(X_train_preprocessed),len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "\n",
    "STOP_WORDS = get_stop_words('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dicts(text, min_count = 1):\n",
    "    \n",
    "    word_dict = {}\n",
    "    words = text.split()\n",
    "   \n",
    "    for word in words:\n",
    "        word_dict[word] = word_dict.get(word,0) + 1\n",
    "        \n",
    "    frequent_words = []\n",
    "    for key, value in word_dict.items():\n",
    "        if value >= min_count and key not in STOP_WORDS:\n",
    "            if key == '.': key = '<dot>'\n",
    "            elif key == ',': key = '<coma>'\n",
    "            frequent_words.append(key)\n",
    "            \n",
    "    word_list = [\"<UNK>\", \"<PAD>\"] + sorted(frequent_words)\n",
    "    \n",
    "    word2idx = {word_list[idx]: idx for idx in range(len(word_list))}\n",
    "    idx2word = {idx: word_list[idx] for idx in range(len(word_list))}\n",
    "    return word2idx, idx2word\n",
    "\n",
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.word2idx = None\n",
    "        self.idx2word = None\n",
    "        \n",
    "    def fit(self, X,min_count):\n",
    "        text = \" \".join(X)\n",
    "        self.word2idx, self.idx2word = create_dicts(text,min_count)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self.transform_line(line) for line in X]\n",
    "        \n",
    "    def transform_line(self, line):\n",
    "        return [self.word2idx.get(self.convert(word), 0) for word in line.split()]\n",
    "    \n",
    "    def convert(self,word):\n",
    "            if word == '.': word = '<dot>'\n",
    "            elif word == ',': word = '<coma>'\n",
    "            return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit(X_train_preprocessed,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = tokenizer.transform(X_train_preprocessed)\n",
    "X_test_tokenized = tokenizer.transform(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = None\n",
    "X_test_preprocessed = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cutter:\n",
    "\n",
    "    def __init__(self, size=150):\n",
    "        self.size = size\n",
    "        \n",
    "    def transform(self, X):\n",
    "        new_X = []\n",
    "        for line in X:\n",
    "            new_line = line[:self.size]\n",
    "            new_line = new_line + [1] * (self.size - len(new_line))\n",
    "            new_X.append(new_line)\n",
    "        return new_X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutter = Cutter()\n",
    "X_train_cutted = cutter.transform(X_train_tokenized)\n",
    "X_test_cutted = cutter.transform(X_test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = None\n",
    "X_test_tokenized = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.from_numpy(y_train.values)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.tensor(X_train_cutted), torch.from_numpy(y_train.values).float())\n",
    "test_data = TensorDataset(torch.tensor(X_test_cutted), torch.from_numpy(y_test.values).float())\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, dict_size, output_size, embedding_dim, hidden_dim, hidden_inter_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(dict_size, embedding_dim)\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_inter_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_inter_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm1(embeded)\n",
    "        #lstm_out = lstm_out[:, -1] \n",
    "        lstm_outer,_ = self.lstm2(lstm_out)\n",
    "        lstm_outer = lstm_outer[:,-1]\n",
    "        logits = self.fc(lstm_outer)\n",
    "        out = self.sigmoid(logits)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_size = len(tokenizer.word2idx)\n",
    "output_size = len(label_colnames)\n",
    "embedding_dim = 3\n",
    "hidden_dim = 4\n",
    "hidden_inter_dim = 3\n",
    "\n",
    "lstm_model = LSTMModel(dict_size, output_size, embedding_dim, hidden_dim,hidden_inter_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load train model\n",
    "\n",
    "# lstm_model.load_state_dict(torch.load(\"models/lstm_model3.pt\"))\n",
    "# lstm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_torch = torch.tensor(X_train_cutted)\n",
    "# X_test_torch = torch.tensor(X_test_cutted)\n",
    "# X_train_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_model(X_train_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4199, 0.4900, 0.5522, 0.5269, 0.5122, 0.4450],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4234, 0.4910, 0.5506, 0.5251, 0.5114, 0.4430],\n",
       "        [0.4174, 0.4912, 0.5523, 0.5295, 0.5102, 0.4463],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440],\n",
       "        [0.4236, 0.4949, 0.5465, 0.5243, 0.5099, 0.4440]],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "input_data, labels = dataiter.next()\n",
    "lstm_model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.05\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 300, Avg. Loss: 0.20460538855443397\n",
      "Epoch: 1, Batch: 600, Avg. Loss: 0.20364939082413913\n",
      "Epoch: 1, Batch: 900, Avg. Loss: 0.20140411200622718\n",
      "Epoch: 2, Batch: 300, Avg. Loss: 0.1745471621491015\n",
      "Epoch: 2, Batch: 600, Avg. Loss: 0.13776160014793276\n",
      "Epoch: 2, Batch: 900, Avg. Loss: 0.13191642358899117\n",
      "Epoch: 3, Batch: 300, Avg. Loss: 0.11910004152605931\n",
      "Epoch: 3, Batch: 600, Avg. Loss: 0.11807065438479185\n",
      "Epoch: 3, Batch: 900, Avg. Loss: 0.12585495902846258\n",
      "Epoch: 4, Batch: 300, Avg. Loss: 0.12126149378716945\n",
      "Epoch: 4, Batch: 600, Avg. Loss: 0.11036608431488276\n",
      "Epoch: 4, Batch: 900, Avg. Loss: 0.11629927508533001\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 4\n",
    "print_every = 300\n",
    "\n",
    "lstm_model.train()\n",
    "optimizer.train = True\n",
    "\n",
    "loss_over_time = [] # to track the loss as the network trains\n",
    "    \n",
    "for epoch in range(n_epoch):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_i, (input_data, labels) in enumerate(train_loader):\n",
    "        # Zero gradients (just in case)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass, calculate predictions\n",
    "        output = lstm_model(input_data) \n",
    "        # Calculate loss\n",
    "        loss = criterion(output, labels)\n",
    "        ## Backward propagation\n",
    "        loss.backward()\n",
    "        ## Upade weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss statistics\n",
    "        # to convert loss into a scalar and add it to running_loss, we use .item()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if batch_i % print_every ==  print_every - 1:    # print everyx batches (\n",
    "                avg_loss = running_loss/print_every\n",
    "                # record and print the avg loss over the 100 batches\n",
    "                loss_over_time.append(avg_loss)\n",
    "                print('Epoch: {}, Batch: {}, Avg. Loss: {}'.format(epoch + 1, batch_i+1, avg_loss))\n",
    "                running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_over_time)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Epoch of Training:\n",
    "\n",
    "1. Type : LSTM-MLP   ; Embeding: 3 ; Hidden Dim : 4   ; LR : 0.005 ; Avg Loss : 0.167 \n",
    "2. Type : LSTM-MLP   ; Embeding: 4 ; Hidden Dim : 4   ; LR : 0.005 ; Avg Loss : 0.173\n",
    "3. Type : LSTM-MLP   ; Embeding: 3 ; Hidden Dim : 2   ; LR : 0.005 ; Avg Loss : 0.171\n",
    "4. Type : LSTM-MLP   ; Embeding: 3 ; Hidden Dim : 3   ; LR : 0.005 ; Avg Loss : 0.174\n",
    "\n",
    "### Four Epochs of Training:\n",
    "\n",
    "5. Type : 2xLSTM-MLP ; Embeding: 3 ; Hidden Dim : 3-4 ; LR : 0.05  ; Avg Loss : 0.116\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print model's state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight \t torch.Size([29467, 3])\n",
      "lstm1.weight_ih_l0 \t torch.Size([16, 3])\n",
      "lstm1.weight_hh_l0 \t torch.Size([16, 4])\n",
      "lstm1.bias_ih_l0 \t torch.Size([16])\n",
      "lstm1.bias_hh_l0 \t torch.Size([16])\n",
      "lstm2.weight_ih_l0 \t torch.Size([12, 4])\n",
      "lstm2.weight_hh_l0 \t torch.Size([12, 3])\n",
      "lstm2.bias_ih_l0 \t torch.Size([12])\n",
      "lstm2.bias_hh_l0 \t torch.Size([12])\n",
      "fc.weight \t torch.Size([6, 3])\n",
      "fc.bias \t torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in lstm_model.state_dict():\n",
    "    print(param_tensor, \"\\t\", lstm_model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_model.state_dict(), \"models/lstm_model3.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def evaluate_classification(y, y_hat, y_proba):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y, y_hat),\n",
    "        \"Precision\": precision_score(y, y_hat),\n",
    "        \"Recall\": recall_score(y, y_hat),\n",
    "        \"F1-score\": f1_score(y, y_hat),\n",
    "        \"AUC\": roc_auc_score(y, y_proba),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.000013\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oriol/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/oriol/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "num_classes = len(label_colnames)\n",
    "# initialize tensor and lists to monitor test loss and accuracy\n",
    "test_loss = torch.zeros(1)\n",
    "class_correct = list(0. for i in range(num_classes))\n",
    "class_total = list(0. for i in range(num_classes))\n",
    "\n",
    "# set the module to evaluation mode\n",
    "lstm_model.eval()\n",
    "\n",
    "# get the input images and their corresponding labels\n",
    "inputs, labels = test_loader.dataset.tensors\n",
    "\n",
    "# forward pass to get outputs\n",
    "outputs = lstm_model(inputs)\n",
    "\n",
    "# calculate the loss\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "# update average test loss \n",
    "test_loss = test_loss + ((torch.ones(1) / (len(labels) + 1)) * (loss.data - test_loss))\n",
    "\n",
    "# get the predicted class from the maximum value in the output-list of class scores\n",
    "metrics = {}\n",
    "for j in range(num_classes):\n",
    "    # compare predictions to true label\n",
    "    predicted_class = np.round(outputs.data[:,j])\n",
    "    labels_class = labels.data[:,j]\n",
    "    class_total[j] = len(labels)\n",
    "    class_correct[j] = (labels_class==predicted_class).sum()\n",
    "    metrics[label_colnames[j]] = evaluate_classification(labels_class, predicted_class, outputs.data[:,j])\n",
    "    #(predicted_class == labels_class).sum()\n",
    "              \n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37566666666666665"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.714+0.180+0.59+0.26+0.0+0.51)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "{'Accuracy': 0.914368795748521, 'F1-score': 0.4019607843137255, 'AUC': 0.7805729364455313, 'Recall': 0.2797270955165692, 'Precision': 0.7139303482587065}\n",
      "severe_toxic\n",
      "{'Accuracy': 0.9722250075203048, 'F1-score': 0.2613333333333333, 'AUC': 0.8872581422571095, 'Recall': 0.47572815533980584, 'Precision': 0.1801470588235294}\n",
      "obscene\n",
      "{'Accuracy': 0.9511681540158428, 'F1-score': 0.47122692725298587, 'AUC': 0.8382656915528678, 'Recall': 0.3916967509025271, 'Precision': 0.5912806539509536}\n",
      "threat\n",
      "{'Accuracy': 0.9968916073398175, 'F1-score': 0.0, 'AUC': 0.8427427466401906, 'Recall': 0.0, 'Precision': 0.0}\n",
      "identity_hate\n",
      "{'Accuracy': 0.9906748220194526, 'F1-score': 0.021052631578947368, 'AUC': 0.8291565750582145, 'Recall': 0.01098901098901099, 'Precision': 0.25}\n",
      "insult\n",
      "{'Accuracy': 0.9500651759751328, 'F1-score': 0.42758620689655175, 'AUC': 0.8343977472633352, 'Recall': 0.36470588235294116, 'Precision': 0.5166666666666667}\n"
     ]
    }
   ],
   "source": [
    "for label in metrics:\n",
    "    print(label)\n",
    "    print(metrics[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Test Loss : 0.000004 ; Accuracy : 0.9608 ; Precision : 0.433\n",
    "2. Test Loss : 0.000004 ; Accuracy : 0.9605 ; Precision : 0.361\n",
    "3. Test Loss : 0.000004 ; Accuracy : 0.9623 ; Precision : 0.0\n",
    "4. Test Loss : 0.000004 ; Accuracy : 0.9630 ; Precision : 0.291\n",
    "5. Test Loss : 0.000013 ; Accuracy : 0.9615 ; Precision : 0.375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 0.4345074859780742, 'Accuracy': 0.9636193484237001, 'Recall': 0.007582406975434276, 'F1-score': 0.014441843174986523, 'AUC': 0.6031137234185818}\n"
     ]
    }
   ],
   "source": [
    "total_evaluation = {}\n",
    "for metric in metrics['toxic']:\n",
    "    total_evaluation[metric] = 0\n",
    "    for label in metrics:\n",
    "        total_evaluation[metric] += metrics[label][metric]\n",
    "    total_evaluation[metric] /= num_classes\n",
    "print(total_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project\n",
    "\n",
    "* Reduce vocabulary size by removing very unfrequent words\n",
    "    * Unfrequent words removed & STOP WORDS\n",
    "* Tokenize dots, comas, etc, into `<dot>`, `<coma>` respectively.\n",
    "    * Mapping function: create_dict & convert\n",
    "* Add another layer of LSTM\n",
    "* Rebalance train dataset by repeating positive example \n",
    "    * Balanced Partition function: min_freq. per each class\n",
    "* Play with parameters.\n",
    "    * Embeding & Hidden Dim\n",
    "\n",
    "## Extra\n",
    "\n",
    "One of the following:\n",
    "* Submit to kaggle\n",
    "* Create generator of comments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
