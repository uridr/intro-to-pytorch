{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "![LSTM](imgs/LSTM3-chain.png)\n",
    "\n",
    "![LSTM](imgs/LSTM2-notation.png)\n",
    "\n",
    "\n",
    "\n",
    "![LSTM](imgs/LSTM3-focus-f.png)\n",
    "\n",
    "![LSTM](imgs/LSTM3-focus-i.png)\n",
    "\n",
    "![LSTM](imgs/LSTM3-focus-C.png)\n",
    "\n",
    "![LSTM](imgs/LSTM3-focus-o.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From pytorch documentation\n",
    "\n",
    "\\begin{array}{ll} \\\\\n",
    "    f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\\\\n",
    "    i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\\\\n",
    "    g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{(t-1)} + b_{hg}) \\\\\n",
    "    c_t = f_t * c_{(t-1)} + i_t * g_t \\\\\n",
    "    o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\\\    \n",
    "    h_t = o_t * \\tanh(c_t) \\\\\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to define LSTM layer in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.9371e-01, -2.0238e+00, -1.3367e+00],\n",
       "         [-7.1214e-01,  3.9357e-01, -8.0636e-01]],\n",
       "\n",
       "        [[ 1.0664e+00, -1.8921e+00,  1.1003e+00],\n",
       "         [ 9.2181e-01,  4.6061e-01, -3.7591e-01]],\n",
       "\n",
       "        [[-1.1430e+00,  1.9850e+00,  6.8247e-01],\n",
       "         [ 6.3254e-01, -1.6362e+00, -6.4329e-01]],\n",
       "\n",
       "        [[ 3.7377e-01, -4.9265e-01, -1.0238e-01],\n",
       "         [ 4.0733e-01,  6.7559e-02, -1.5383e+00]],\n",
       "\n",
       "        [[ 3.5512e-02,  7.9347e-02,  6.2202e-01],\n",
       "         [ 1.2980e+00, -1.5078e-03, -1.3330e+00]],\n",
       "\n",
       "        [[ 6.5556e-02, -2.8847e-01,  4.2900e-01],\n",
       "         [ 3.1263e-02, -5.2232e-03,  5.5556e-01]],\n",
       "\n",
       "        [[ 2.9324e-02,  2.9765e-01, -8.5468e-01],\n",
       "         [ 2.6762e-01, -3.6226e-01, -1.6829e+00]],\n",
       "\n",
       "        [[-1.8964e-01, -2.9445e-01, -8.9548e-01],\n",
       "         [-2.6878e+00, -7.7660e-01, -2.7466e-01]],\n",
       "\n",
       "        [[ 5.9321e-01, -1.4983e+00, -3.5858e-01],\n",
       "         [-6.0709e-01, -7.1092e-01, -1.6367e+00]],\n",
       "\n",
       "        [[ 4.7706e-01,  1.4737e+00, -3.9085e-01],\n",
       "         [-1.4603e+00,  4.7680e-01,  1.4279e-01]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 10\n",
    "input_size = 3\n",
    "hidden_size = 4 \n",
    "\n",
    "inputs = torch.randn(seq_len, batch_size, input_size)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hidden_0 = (h_0, c_0)\n",
    "hidden_0 = (torch.zeros(1, batch_size, hidden_size), torch.zeros(1, batch_size, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out, lstm_hidden = lstm(inputs)\n",
    "lstm_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1161, -0.0449,  0.1356, -0.0908],\n",
       "         [ 0.0797, -0.1030, -0.0519, -0.0097]],\n",
       "\n",
       "        [[ 0.2028, -0.1207,  0.0942, -0.0380],\n",
       "         [ 0.0988, -0.0903,  0.1654,  0.0538]],\n",
       "\n",
       "        [[ 0.1246, -0.0615,  0.2019, -0.0452],\n",
       "         [-0.0669, -0.2622, -0.1729,  0.1506]],\n",
       "\n",
       "        [[ 0.1125, -0.1810,  0.0160,  0.0975],\n",
       "         [ 0.0633, -0.2287, -0.0961,  0.1149]],\n",
       "\n",
       "        [[ 0.1426, -0.1711,  0.0510,  0.0349],\n",
       "         [ 0.0473, -0.2513, -0.1071,  0.0590]],\n",
       "\n",
       "        [[ 0.0526, -0.2139,  0.0484,  0.1440],\n",
       "         [ 0.0955, -0.2225,  0.0076,  0.0419]],\n",
       "\n",
       "        [[ 0.0832, -0.1676,  0.1285,  0.1490],\n",
       "         [-0.0626, -0.2704, -0.0761,  0.1422]],\n",
       "\n",
       "        [[ 0.1588, -0.0668,  0.1662, -0.1116],\n",
       "         [ 0.0823, -0.2291, -0.0254,  0.0449]],\n",
       "\n",
       "        [[ 0.1449, -0.1012,  0.1712, -0.1042],\n",
       "         [ 0.0258, -0.2339,  0.0712,  0.1279]],\n",
       "\n",
       "        [[ 0.0864, -0.1954,  0.0454,  0.1037],\n",
       "         [ 0.1143, -0.0547,  0.1980,  0.0086]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to put hidden inputs to zeros, there is no need to provide them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1161, -0.0449,  0.1356, -0.0908],\n",
       "         [ 0.0797, -0.1030, -0.0519, -0.0097]],\n",
       "\n",
       "        [[ 0.2028, -0.1207,  0.0942, -0.0380],\n",
       "         [ 0.0988, -0.0903,  0.1654,  0.0538]],\n",
       "\n",
       "        [[ 0.1246, -0.0615,  0.2019, -0.0452],\n",
       "         [-0.0669, -0.2622, -0.1729,  0.1506]],\n",
       "\n",
       "        [[ 0.1125, -0.1810,  0.0160,  0.0975],\n",
       "         [ 0.0633, -0.2287, -0.0961,  0.1149]],\n",
       "\n",
       "        [[ 0.1426, -0.1711,  0.0510,  0.0349],\n",
       "         [ 0.0473, -0.2513, -0.1071,  0.0590]],\n",
       "\n",
       "        [[ 0.0526, -0.2139,  0.0484,  0.1440],\n",
       "         [ 0.0955, -0.2225,  0.0076,  0.0419]],\n",
       "\n",
       "        [[ 0.0832, -0.1676,  0.1285,  0.1490],\n",
       "         [-0.0626, -0.2704, -0.0761,  0.1422]],\n",
       "\n",
       "        [[ 0.1588, -0.0668,  0.1662, -0.1116],\n",
       "         [ 0.0823, -0.2291, -0.0254,  0.0449]],\n",
       "\n",
       "        [[ 0.1449, -0.1012,  0.1712, -0.1042],\n",
       "         [ 0.0258, -0.2339,  0.0712,  0.1279]],\n",
       "\n",
       "        [[ 0.0864, -0.1954,  0.0454,  0.1037],\n",
       "         [ 0.1143, -0.0547,  0.1980,  0.0086]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out, lstm_hidden = lstm(inputs)\n",
    "lstm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the last output is the output of RRR. We can get it by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0864, -0.1954,  0.0454,  0.1037],\n",
       "        [ 0.1143, -0.0547,  0.1980,  0.0086]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often convient to have batches as the first dimension of the input. One can do it by adding `batch_first=True` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2054, -0.8651, -0.6088],\n",
       "         [ 1.1406,  0.6082, -1.6735],\n",
       "         [ 0.1723,  0.3467,  0.4114],\n",
       "         [-1.9259, -0.2567, -1.2048],\n",
       "         [-1.6136,  1.3430, -0.4050],\n",
       "         [ 1.1966, -1.6512, -0.6767],\n",
       "         [-0.2106, -2.3519,  0.2720],\n",
       "         [-0.1093,  1.0253, -0.1260],\n",
       "         [-1.0609,  0.8758,  0.2576],\n",
       "         [ 0.8765,  1.4954, -0.0666]],\n",
       "\n",
       "        [[-0.0217,  1.5338, -1.4219],\n",
       "         [ 0.2273, -0.3218,  0.3919],\n",
       "         [ 0.0749,  0.4817, -1.1825],\n",
       "         [ 2.1782, -0.3505,  1.3469],\n",
       "         [-0.4601,  1.3531, -0.0419],\n",
       "         [ 0.0473, -0.6126,  0.4255],\n",
       "         [-0.3531, -1.0316,  0.5059],\n",
       "         [ 0.5735,  0.4778,  0.5165],\n",
       "         [-1.7511,  0.0114, -0.2766],\n",
       "         [-1.0167,  1.3915, -0.7804]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_batch_first = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True) \n",
    "inputs_batch_first = torch.randn(batch_size, seq_len, input_size)\n",
    "inputs_batch_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0567,  0.1265,  0.0624,  0.2018],\n",
       "         [-0.1659,  0.3151, -0.1186,  0.3846],\n",
       "         [-0.1493,  0.0682, -0.0403,  0.2772],\n",
       "         [-0.3941, -0.1411,  0.0983,  0.2673],\n",
       "         [-0.4439, -0.2128, -0.0445,  0.2855],\n",
       "         [-0.1648, -0.0416,  0.0435,  0.1917],\n",
       "         [-0.0991, -0.1108,  0.0799,  0.1383],\n",
       "         [-0.1874, -0.0555,  0.0368,  0.3100],\n",
       "         [-0.2655, -0.1287,  0.0010,  0.2873],\n",
       "         [-0.1702,  0.0646, -0.2415,  0.3772]],\n",
       "\n",
       "        [[-0.1996,  0.1648, -0.2542,  0.3286],\n",
       "         [-0.1348,  0.0275, -0.0138,  0.2211],\n",
       "         [-0.2382,  0.1150, -0.0923,  0.3565],\n",
       "         [-0.0244,  0.0877, -0.0228,  0.2297],\n",
       "         [-0.1829,  0.0225, -0.1591,  0.3706],\n",
       "         [-0.1361, -0.0329,  0.0252,  0.2318],\n",
       "         [-0.1136, -0.1019,  0.1046,  0.2007],\n",
       "         [-0.1038, -0.0251,  0.0933,  0.2877],\n",
       "         [-0.3108, -0.1780,  0.1325,  0.2571],\n",
       "         [-0.3798, -0.1602, -0.0726,  0.3382]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out, lstm_hidden = lstm_batch_first(inputs_batch_first)\n",
    "lstm_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we get the finial output by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1702,  0.0646, -0.2415,  0.3772],\n",
       "        [-0.3798, -0.1602, -0.0726,  0.3382]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[36, 67, 43, 95, 89,  8, 59, 93, 73, 69],\n",
       "        [47, 66, 68, 29, 70, 16, 58, 13, 37, 94]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_size = 100\n",
    "sentences = torch.randint(dict_size, (batch_size, seq_len))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 3\n",
    "embedding = nn.Embedding(dict_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0091, -0.3593, -1.0621],\n",
       "         [-1.7992, -0.0894,  1.2168],\n",
       "         [ 0.4249, -0.9113, -0.9369],\n",
       "         [ 1.7890, -1.0901,  0.7563],\n",
       "         [-0.6374,  1.1834,  0.6713],\n",
       "         [-1.2554, -1.4542, -0.3407],\n",
       "         [-1.1324, -0.4685,  0.5710],\n",
       "         [ 0.0318,  1.0612,  1.9154],\n",
       "         [ 0.0588,  0.8046,  0.2209],\n",
       "         [ 0.0756, -0.6359, -1.8824]],\n",
       "\n",
       "        [[-0.0348,  0.9834, -0.2814],\n",
       "         [ 0.1302, -0.7690, -1.2987],\n",
       "         [-1.1199, -0.3056, -0.0716],\n",
       "         [-1.2604,  1.3658,  0.7427],\n",
       "         [-1.5014,  0.6390, -0.5878],\n",
       "         [-0.7691,  1.7891,  0.6372],\n",
       "         [ 1.7406,  0.4675,  0.0660],\n",
       "         [ 1.0832, -0.4642,  0.7879],\n",
       "         [ 0.0817, -0.8927,  0.7386],\n",
       "         [-0.0728,  0.7193, -0.5492]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_embedded = embedding(sentences)\n",
    "sentences_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2681,  0.0815,  0.0451,  0.3268],\n",
       "        [-0.1928,  0.0247,  0.0008,  0.3499]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_out, _ = lstm_batch_first(sentences_embedded)\n",
    "lstm_out[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing (NLP)\n",
    "\n",
    "Next we consider a dataset with text and the goal is to evaluate whether they are toxic or non-toxic.\n",
    "\n",
    "You can download the dataset in the following link:\n",
    "\n",
    "[here](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comments_df = pd.read_csv(\"data/jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "comments_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27250</th>\n",
       "      <td>I'm afraid that you didn't follow the history ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133958</th>\n",
       "      <td>Drmies, you really need to be de-syoped.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text\n",
       "27250   I'm afraid that you didn't follow the history ...\n",
       "133958           Drmies, you really need to be de-syoped."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "label_colnames = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(comments_df[['comment_text']], comments_df[label_colnames], random_state=667)\n",
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "import random\n",
    "from nltk.stem import SnowballStemmer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z ]')\n",
    "STEMMER = SnowballStemmer('english')\n",
    "\n",
    "class TextPreprocessor:\n",
    "        \n",
    "    def transfrom_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(BAD_SYMBOLS_RE, \" \", text) # process bad symbols\n",
    "        # text = \" \".join([STEMMER.stem(word) for word in text.split()])\n",
    "        return text\n",
    "    \n",
    "    def transform(self, series):\n",
    "        return series.apply(lambda text: self.transfrom_text(text))\n",
    "    \n",
    "    def labels_to_text(self, text, extra_labels):\n",
    "        for idx in extra_labels.index:\n",
    "            text = text.append(text.loc[[idx]])                \n",
    "        return text    \n",
    "    \n",
    "    def over_sampling(self,text,labels,extra_positive):\n",
    "        extra_labels = pd.DataFrame()\n",
    "        for idx in range(len(extra_positive)):\n",
    "            target = extra_positive[idx]\n",
    "            if idx == 0:\n",
    "                extra_labels = labels.groupby([target]).get_group(1)\n",
    "            else:\n",
    "                prev_target = extra_positive[idx-1]\n",
    "                extra_labels = extra_labels[extra_labels[target] == extra_labels[prev_target]]\n",
    "        \n",
    "        labels = labels.append(extra_labels)\n",
    "        print(len(text))\n",
    "        text = self.labels_to_text(text,extra_labels)\n",
    "        print(len(text))\n",
    "        return text,labels\n",
    "    \n",
    "    def balanced_partition(self,text,labels,min_freq):\n",
    "        while True:\n",
    "            labels_dist = labels.sum()/len(labels)\n",
    "            extra_positive = []\n",
    "            for label in labels_dist.keys():\n",
    "                if labels_dist[label] < min_freq:\n",
    "                    extra_positive.append(label) \n",
    "            if len(extra_positive) == 0: \n",
    "                return text,labels\n",
    "            else: \n",
    "                text,labels = self.over_sampling(text,labels,extra_positive)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0.095857\n",
       "severe_toxic     0.010002\n",
       "obscene          0.053226\n",
       "threat           0.003008\n",
       "insult           0.049600\n",
       "identity_hate    0.008782\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119678\n",
      "119702\n",
      "119702\n",
      "119846\n",
      "119846\n",
      "122726\n",
      "122726\n",
      "906086\n",
      "906086\n"
     ]
    }
   ],
   "source": [
    "preprocessor = TextPreprocessor()\n",
    "X_train_trs = preprocessor.transform(X_train['comment_text'])\n",
    "X_train_preprocessed, y_train = preprocessor.balanced_partition(X_train_trs,y_train,0.02)\n",
    "X_test_preprocessed = preprocessor.transform(X_test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0.124865\n",
       "severe_toxic     0.035762\n",
       "obscene          0.079938\n",
       "threat           0.035689\n",
       "insult           0.076576\n",
       "identity_hate    0.034243\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm afraid that you didn't follow the history of all this. (1) I don't want to obtain an email, I want to write it. (2) Every time when someone makes a remark, I tend to think that I am obligated to reply, since otherwise that person may think  that I neglect him/her, and don't think him or her worthy of a reply. But that leaves me no time to write that email. (3) Also, if I would take that time, then Rspeer could delete all my contributions in the mean time, as he already has started to do,  making it hard work again to restore it. (4) I recognize that wikipedia can be accessed any time of the day, but it might be proper for you and Rspeer and others reading my request for a time out to respect my wish for it. (5) Rspeer started  this discussion about my conduct on this talk page, by saying that there was a threat, while there wasn't. Now, do I have to take this seriously ? And have this nonsense here ? (6) Should I have entered my criticism on his behaviour on his talk page, instead of the borda fixed point page, where he occluded the argument on the article with his behavior ? (7) My impression now is that I have to ask for mediation to get some quiet time to formulate my argument on the integrity of science for the professors. True of false ?\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "i m afraid that you didn t follow the history of all this   1  i don t want to obtain an email  i want to write it   2  every time when someone makes a remark  i tend to think that i am obligated to reply  since otherwise that person may think  that i neglect him her  and don t think him or her worthy of a reply  but that leaves me no time to write that email   3  also  if i would take that time  then rspeer could delete all my contributions in the mean time  as he already has started to do   making it hard work again to restore it   4  i recognize that wikipedia can be accessed any time of the day  but it might be proper for you and rspeer and others reading my request for a time out to respect my wish for it   5  rspeer started  this discussion about my conduct on this talk page  by saying that there was a threat  while there wasn t  now  do i have to take this seriously   and have this nonsense here    6  should i have entered my criticism on his behaviour on his talk page  instead of the borda fixed point page  where he occluded the argument on the article with his behavior    7  my impression now is that i have to ask for mediation to get some quiet time to formulate my argument on the integrity of science for the professors  true of false  \n"
     ]
    }
   ],
   "source": [
    "print(X_train[\"comment_text\"].iloc[0])\n",
    "print('---------------------------------------------------------------------------------------------------------------------')\n",
    "print(X_train_preprocessed.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drmies, you really need to be de-syoped.\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "drmies  you really need to be de syoped \n"
     ]
    }
   ],
   "source": [
    "print(X_train[\"comment_text\"].iloc[1])\n",
    "print('---------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "print(X_train_preprocessed.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "\n",
    "STOP_WORDS = get_stop_words('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dicts(text, min_count = 1):\n",
    "    \n",
    "    word_dict = {}\n",
    "    words = text.split()\n",
    "   \n",
    "    for word in words:\n",
    "        word_dict[word] = word_dict.get(word,0) + 1\n",
    "        \n",
    "    frequent_words = []\n",
    "    for key, value in word_dict.items():\n",
    "        if value >= min_count and key not in STOP_WORDS:\n",
    "            frequent_words.append(key)\n",
    "            \n",
    "    word_list = [\"<UNK>\", \"<PAD>\"] + sorted(frequent_words)\n",
    "    \n",
    "    word2idx = {word_list[idx]: idx for idx in range(len(word_list))}\n",
    "    idx2word = {idx: word_list[idx] for idx in range(len(word_list))}\n",
    "    return word2idx, idx2word\n",
    "\n",
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.word2idx = None\n",
    "        self.idx2word = None\n",
    "        \n",
    "    def fit(self, X,min_count):\n",
    "        text = \" \".join(X)\n",
    "        self.word2idx, self.idx2word = create_dicts(text,min_count)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self.transform_line(line) for line in X]\n",
    "        \n",
    "    def transform_line(self, line):\n",
    "        return [self.word2idx.get(word, 0) for word in line.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit(X_train_preprocessed,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = tokenizer.transform(X_train_preprocessed)\n",
    "X_test_tokenized = tokenizer.transform(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cutter:\n",
    "\n",
    "    def __init__(self, size=150):\n",
    "        self.size = size\n",
    "        \n",
    "    def transform(self, X):\n",
    "        new_X = []\n",
    "        for line in X:\n",
    "            new_line = line[:self.size]\n",
    "            new_line = new_line + [1] * (self.size - len(new_line))\n",
    "            new_X.append(new_line)\n",
    "        return new_X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutter = Cutter()\n",
    "X_train_cutted = cutter.transform(X_train_tokenized)\n",
    "X_test_cutted = cutter.transform(X_test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.from_numpy(y_train.values)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123734, 119678)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train.values),len(X_train_cutted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-c25f03b90818>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cutted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_cutted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data = TensorDataset(torch.tensor(X_train_cutted), torch.from_numpy(y_train.values).float())\n",
    "test_data = TensorDataset(torch.tensor(X_test_cutted), torch.from_numpy(y_test.values).float())\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, dict_size, output_size, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(dict_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embeded)\n",
    "        lstm_out = lstm_out[:, -1]        \n",
    "        logits = self.fc(lstm_out)\n",
    "        out = self.sigmoid(logits)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_size = len(tokenizer.word2idx)\n",
    "output_size = len(label_colnames)\n",
    "embedding_dim = 3\n",
    "hidden_dim = 4\n",
    "\n",
    "lstm_model = LSTMModel(dict_size, output_size, embedding_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52634"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Load train model\n",
    "\n",
    "#lstm_model.load_state_dict(torch.load(\"models/lstm_model2.pt\"))\n",
    "#lstm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([119678, 150])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_torch = torch.tensor(X_train_cutted)\n",
    "X_test_torch = torch.tensor(X_test_cutted)\n",
    "X_train_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:56] posix_memalign(&data, gAlignment, nbytes) == 0. 12 vs 0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-955aa1357c3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_torch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-f64de1fbf69a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0membeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m         return F.embedding(\n\u001b[1;32m    116\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:56] posix_memalign(&data, gAlignment, nbytes) == 0. 12 vs 0\n"
     ]
    }
   ],
   "source": [
    "lstm_model(X_train_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4976, 0.4367, 0.5084, 0.4591, 0.4739, 0.5399],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.4962, 0.4523, 0.5124, 0.4392, 0.4517, 0.5386],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406],\n",
       "        [0.5069, 0.4261, 0.5184, 0.4666, 0.4759, 0.5515],\n",
       "        [0.4964, 0.4329, 0.5086, 0.4614, 0.4750, 0.5406]],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "input_data, labels = dataiter.next()\n",
    "lstm_model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.005\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 300, Avg. Loss: 0.2131408823405703\n",
      "Epoch: 1, Batch: 600, Avg. Loss: 0.14664325001339118\n",
      "Epoch: 1, Batch: 900, Avg. Loss: 0.138851909575363\n",
      "Epoch: 1, Batch: 1200, Avg. Loss: 0.13903380391498407\n",
      "Epoch: 1, Batch: 1500, Avg. Loss: 0.1424761813879013\n",
      "Epoch: 1, Batch: 1800, Avg. Loss: 0.13652350347489117\n",
      "Epoch: 1, Batch: 2100, Avg. Loss: 0.14388270065188408\n",
      "Epoch: 1, Batch: 2400, Avg. Loss: 0.14021911654621363\n",
      "Epoch: 1, Batch: 2700, Avg. Loss: 0.14167805507779122\n",
      "Epoch: 1, Batch: 3000, Avg. Loss: 0.140565021323661\n",
      "Epoch: 1, Batch: 3300, Avg. Loss: 0.14060406055301428\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 1\n",
    "print_every = 300\n",
    "\n",
    "loss_over_time = [] # to track the loss as the network trains\n",
    "    \n",
    "for epoch in range(n_epoch):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_i, (input_data, labels) in enumerate(train_loader):\n",
    "        # Zero gradients (just in case)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass, calculate predictions\n",
    "        output = lstm_model(input_data) \n",
    "        # Calculate loss\n",
    "        loss = criterion(output, labels)\n",
    "        ## Backward propagation\n",
    "        loss.backward()\n",
    "        ## Upade weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss statistics\n",
    "        # to convert loss into a scalar and add it to running_loss, we use .item()\n",
    "        running_loss += loss.item()\n",
    "            \n",
    "        \n",
    "        if batch_i % print_every ==  print_every - 1:    # print everyx batches (\n",
    "                avg_loss = running_loss/print_every\n",
    "                # record and print the avg loss over the 100 batches\n",
    "                loss_over_time.append(avg_loss)\n",
    "                print('Epoch: {}, Batch: {}, Avg. Loss: {}'.format(epoch + 1, batch_i+1, avg_loss))\n",
    "                running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_over_time)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print model's state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.weight \t torch.Size([153998, 3])\n",
      "lstm.weight_ih_l0 \t torch.Size([16, 3])\n",
      "lstm.weight_hh_l0 \t torch.Size([16, 4])\n",
      "lstm.bias_ih_l0 \t torch.Size([16])\n",
      "lstm.bias_hh_l0 \t torch.Size([16])\n",
      "fc.weight \t torch.Size([6, 4])\n",
      "fc.bias \t torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in lstm_model.state_dict():\n",
    "    print(param_tensor, \"\\t\", lstm_model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_model.state_dict(), \"models/lstm_model2.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def evaluate_classification(y, y_hat, y_proba):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y, y_hat),\n",
    "        \"Precision\": precision_score(y, y_hat),\n",
    "        \"Recall\": recall_score(y, y_hat),\n",
    "        \"F1-score\": f1_score(y, y_hat),\n",
    "        \"AUC\": roc_auc_score(y, y_proba),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.000002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yc00122/.virtualenvs/py3.6.8-pytorch/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/yc00122/.virtualenvs/py3.6.8-pytorch/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/yc00122/.virtualenvs/py3.6.8-pytorch/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/yc00122/.virtualenvs/py3.6.8-pytorch/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "num_classes = len(label_colnames)\n",
    "# initialize tensor and lists to monitor test loss and accuracy\n",
    "test_loss = torch.zeros(1)\n",
    "class_correct = list(0. for i in range(num_classes))\n",
    "class_total = list(0. for i in range(num_classes))\n",
    "\n",
    "# set the module to evaluation mode\n",
    "lstm_model.eval()\n",
    "\n",
    "# get the input images and their corresponding labels\n",
    "inputs, labels = test_loader.dataset.tensors\n",
    "\n",
    "# forward pass to get outputs\n",
    "outputs = lstm_model(inputs)\n",
    "\n",
    "# calculate the loss\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "# update average test loss \n",
    "test_loss = test_loss + ((torch.ones(1) / (len(labels) + 1)) * (loss.data - test_loss))\n",
    "\n",
    "# get the predicted class from the maximum value in the output-list of class scores\n",
    "metrics = {}\n",
    "for j in range(num_classes):\n",
    "    # compare predictions to true label\n",
    "    predicted_class = np.round(outputs.data[:,j])\n",
    "    labels_class = labels.data[:,j]\n",
    "    class_total[j] = len(labels)\n",
    "    class_correct[j] = (labels_class==predicted_class).sum()\n",
    "    metrics[label_colnames[j]] = evaluate_classification(labels_class, predicted_class, outputs.data[:,j])\n",
    "    #(predicted_class == labels_class).sum()\n",
    "              \n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "{'Accuracy': 0.9471586493871105, 'Precision': 0.7083130772970345, 'Recall': 0.7624280481423339, 'F1-score': 0.7343749999999999, 'AUC': 0.947535114514326}\n",
      "severe_toxic\n",
      "{'Accuracy': 0.9900233123605645, 'Precision': 0.5, 'Recall': 0.2663316582914573, 'F1-score': 0.3475409836065574, 'AUC': 0.9861518950620937}\n",
      "obscene\n",
      "{'Accuracy': 0.975785225478154, 'Precision': 0.7770034843205574, 'Recall': 0.7508417508417509, 'F1-score': 0.7636986301369861, 'AUC': 0.9764002317818363}\n",
      "threat\n",
      "{'Accuracy': 0.9970420875842879, 'Precision': 0.0, 'Recall': 0.0, 'F1-score': 0.0, 'AUC': 0.9515710191863128}\n",
      "insult\n",
      "{'Accuracy': 0.9699947359185822, 'Precision': 0.7064372918978913, 'Recall': 0.6558475012879958, 'F1-score': 0.6802030456852792, 'AUC': 0.9676557668657957}\n",
      "identity_hate\n",
      "{'Accuracy': 0.9911262627528639, 'Precision': 0.0, 'Recall': 0.0, 'F1-score': 0.0, 'AUC': 0.9531048726402295}\n"
     ]
    }
   ],
   "source": [
    "for label in metrics:\n",
    "    print(label)\n",
    "    print(metrics[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.9785217122469273, 'Precision': 0.44862564225258056, 'Recall': 0.40590815976058964, 'F1-score': 0.42096960990480375, 'AUC': 0.9637364833417656}\n"
     ]
    }
   ],
   "source": [
    "total_evaluation = {}\n",
    "for metric in metrics['toxic']:\n",
    "    total_evaluation[metric] = 0\n",
    "    for label in metrics:\n",
    "        total_evaluation[metric] += metrics[label][metric]\n",
    "    total_evaluation[metric] /= num_classes\n",
    "print(total_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final project\n",
    "\n",
    "* Reduce vocabulary size by removing very unfrequent words\n",
    "    * Unfrequent words removed + STOP WORDS\n",
    "* Tokenize dots, comas, etc, into `<dot>`, `<coma>` respectively.\n",
    "* Add another layer of LSTM\n",
    "* Rebalance train dataset by repeating positive example \n",
    "    * Balanced Partition function: min_freq. per each class\n",
    "* Play with parameters.\n",
    "\n",
    "## Extra\n",
    "\n",
    "One of the following:\n",
    "* Submit to kaggle\n",
    "* Create generator of comments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
